{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(64, 1, 28, 28)\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.encoder(x)\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        return z\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "        # return val_loss\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test\", test_loss, prog_bar=True)\n",
    "        # return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = FashionMNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset, batch_size=64, num_workers=19,persistent_workers=True,pin_memory=True,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(dataset, len(dataset), num_workers=19, persistent_workers=True,pin_memory=True,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params | In sizes  | Out sizes\n",
      "---------------------------------------------------------------\n",
      "0 | encoder | Sequential | 50.4 K | [64, 784] | [64, 3]  \n",
      "1 | decoder | Sequential | 51.2 K | ?         | ?        \n",
      "---------------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2962333d96874a01bfa1d8ba2447e782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d71aa4f68bb4d79be30b13001d2afd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6367a077a949dba8b8df6b179d0fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b45068e577c4272be88019fde4f984c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                         \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                          \t|  -              \t|  67704          \t|  31.422         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                             \t|  11.414         \t|  2              \t|  22.828         \t|  72.65          \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                     \t|  4.5627         \t|  3              \t|  13.688         \t|  43.562         \t|\n",
      "|  run_training_batch                                                                                                                                             \t|  0.0038417      \t|  1876           \t|  7.207          \t|  22.936         \t|\n",
      "|  [LightningModule]LitAutoEncoder.optimizer_step                                                                                                                 \t|  0.0037836      \t|  1876           \t|  7.098          \t|  22.589         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                     \t|  0.002557       \t|  1876           \t|  4.797          \t|  15.266         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                   \t|  0.0014467      \t|  1876           \t|  2.714          \t|  8.6373         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                        \t|  0.0011738      \t|  1876           \t|  2.202          \t|  7.0078         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                   \t|  0.00087473     \t|  1876           \t|  1.641          \t|  5.2225         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                 \t|  0.00032624     \t|  1879           \t|  0.613          \t|  1.9509         \t|\n",
      "|  [LightningModule]LitAutoEncoder.transfer_batch_to_device                                                                                                       \t|  0.00028457     \t|  1880           \t|  0.535          \t|  1.7026         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  4.2644e-05     \t|  1876           \t|  0.08           \t|  0.2546         \t|\n",
      "|  [LightningModule]LitAutoEncoder.optimizer_zero_grad                                                                                                            \t|  3.2516e-05     \t|  1876           \t|  0.061          \t|  0.19413        \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_gradient_clipping                                                                                                    \t|  1.7058e-05     \t|  1876           \t|  0.032          \t|  0.10184        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                  \t|  0.010333       \t|  3              \t|  0.031          \t|  0.098657       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                            \t|  0.0053333      \t|  3              \t|  0.016          \t|  0.05092        \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                    \t|  8.5288e-06     \t|  1876           \t|  0.016          \t|  0.05092        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                    \t|  0.0053333      \t|  3              \t|  0.016          \t|  0.05092        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  8.5288e-06     \t|  1876           \t|  0.016          \t|  0.05092        \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                       \t|  8.5288e-06     \t|  1876           \t|  0.016          \t|  0.05092        \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                      \t|  8.5288e-06     \t|  1876           \t|  0.016          \t|  0.05092        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.008          \t|  2              \t|  0.016          \t|  0.05092        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                 \t|  0.0075         \t|  2              \t|  0.015          \t|  0.047737       \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                     \t|  7.9957e-06     \t|  1876           \t|  0.015          \t|  0.047737       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_optimizer_step                                                                                                       \t|  7.9957e-06     \t|  1876           \t|  0.015          \t|  0.047737       \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_batch_end                                                                                                             \t|  7.9957e-06     \t|  1876           \t|  0.015          \t|  0.047737       \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                \t|  0.015          \t|  1              \t|  0.015          \t|  0.047737       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  7.9957e-06     \t|  1876           \t|  0.015          \t|  0.047737       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                   \t|  7.9957e-06     \t|  1876           \t|  0.015          \t|  0.047737       \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                      \t|  7.9957e-06     \t|  1876           \t|  0.015          \t|  0.047737       \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_callbacks                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.prepare_data                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.setup                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.configure_optimizers                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_batch_transfer                                                                                                       \t|  0.0            \t|  1880           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_after_batch_transfer                                                                                                        \t|  0.0            \t|  1880           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_fit_start                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_model_eval                                                                                                       \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                     \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_start                                                                                                            \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                             \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                            \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                               \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_epoch_start                                                                                                      \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                               \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_batch_start                                                                                                      \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                 \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                              \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                 \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_batch_end                                                                                                        \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                              \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                 \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_epoch_end                                                                                                        \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                       \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_end                                                                                                              \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                               \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_model_train                                                                                                      \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_start                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_epoch_start                                                                                                           \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                 \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                    \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_batch_start                                                                                                           \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                            \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                  \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_zero_grad                                                                                                            \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_before_backward                                                                                                             \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_after_backward                                                                                                              \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                             \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  0.0            \t|  1876           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_validation_model_zero_grad                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                   \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                      \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_epoch_end                                                                                                             \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                   \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                      \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_save_checkpoint                                                                                                             \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_train_end                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.on_fit_end                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LitAutoEncoder.teardown                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
    "# model\n",
    "autoencoder = LitAutoEncoder()\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", \n",
    "                                    min_delta=0.00, \n",
    "                                    patience=0, \n",
    "                                    verbose=True, \n",
    "                                    mode=\"min\")\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(max_epochs=2, default_root_dir=os.path.join(os.getcwd(), 'lightning_ckpts'),\n",
    "                    callbacks=[], logger=logger, precision=\"16-mixed\", profiler=\"simple\")\n",
    "model=autoencoder\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf606631a8d4494b88b8c62ffb10c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           test            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.026734165847301483    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m          test           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.026734165847301483   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test': 0.026734165847301483}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=autoencoder, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6010 (pid 28848), started 0:02:05 ago. (Use '!kill 28848' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-12233403363d22a1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-12233403363d22a1\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6010;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./lightning_ckpts/lightning_logs/version_8/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b9bc7d7c934880ac8f601771b8b0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LitAutoEncoder.load_from_checkpoint(os.path.join(os.getcwd(), \n",
    "                                        'lightning_ckpts', 'lightning_logs',\n",
    "                                        'version_4', 'checkpoints', \n",
    "                                        'epoch=1-step=1876.ckpt'))\n",
    "# model.eval()\n",
    "# model(torch.rand(1, 28, 28, device=model.device))\n",
    "trainer = L.Trainer()\n",
    "predictions = trainer.predict(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 3])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def __init__(self, in_channels: int, out_channels: int, hidden_size: int, patch_size: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.positional_embeds = nn.Embedding(100000, hidden_size)\n",
    "        self.register_buffer(\"positional_ids\", torch.arange(100000).unsqueeze(0))\n",
    "        self.patch_conv = nn.Conv2d(in_channels, hidden_size, patch_size, stride=patch_size)\n",
    "        self.patch_deconv = nn.ConvTranspose2d(hidden_size, out_channels, patch_size, stride=patch_size)\n",
    "        self.model = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                hidden_size,\n",
    "                hidden_size // 64,\n",
    "                hidden_size * 8 // 3,\n",
    "                activation=F.silu,\n",
    "                batch_first=True,\n",
    "                norm_first=True,\n",
    "            ),\n",
    "            num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        hidden = self.patch_conv(x)\n",
    "        n_seq = hidden.shape[2] * hidden.shape[3]\n",
    "        pos_embeds = self.positional_embeds(self.positional_ids[:, :n_seq]).expand(hidden.shape[0], -1, -1)\n",
    "        output = self.model(hidden.flatten(2).transpose(1, 2) + pos_embeds).transpose(-1, -2).view_as(hidden)\n",
    "        output = self.patch_deconv(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 16, 16])\n",
      "torch.Size([64, 256, 32])\n",
      "torch.Size([64, 32, 256])\n",
      "torch.Size([64, 256, 32])\n"
     ]
    }
   ],
   "source": [
    "in_channels=8\n",
    "out_channels=32\n",
    "hidden_size=32\n",
    "patch_size=(2,4)\n",
    "num_layers=1\n",
    "a = torch.rand((64, 8, 32, 64))\n",
    "\n",
    "patch_conv = nn.Conv2d(in_channels, hidden_size, patch_size, stride=patch_size)\n",
    "a=patch_conv(a)\n",
    "# torch.Size([64, 32, 16, 16])\n",
    "print(a.shape)\n",
    "n_seq = a.shape[2] * a.shape[3]\n",
    "positional_embeds = nn.Embedding(100000, hidden_size)\n",
    "# register_buffer(\"positional_ids\", torch.arange(100000).unsqueeze(0))\n",
    "positional_ids = torch.arange(100000).unsqueeze(0).detach()\n",
    "pos_embeds = positional_embeds(positional_ids[:, :n_seq]).expand(a.shape[0], -1, -1)\n",
    "print(pos_embeds.shape)\n",
    "print(a.flatten(2).shape)\n",
    "print(a.flatten(2).transpose(1, 2).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
